import streamlit as st
import pandas as pd
import joblib
import json
import numpy as np
import os
from PIL import Image

# ============================================
# CONFIGURATION
# ============================================
st.set_page_config(
    page_title="Bug Predictor",
    page_icon="üêõ",
    layout="wide"
)

# Chemins
MODEL_DIR = r'C:\Users\M9-electro\Desktop\bug-predictor\models'
FIGURES_DIR = r'C:\Users\M9-electro\Desktop\bug-predictor\results\figures'
DATA_DIR = r'C:\Users\M9-electro\Desktop\bug-predictor\data\processed'

# ============================================
# CHARGEMENT DU MOD√àLE
# ============================================
@st.cache_resource
def load_model():
    try:
        model = joblib.load(os.path.join(MODEL_DIR, 'best_model.pkl'))
        scaler = joblib.load(os.path.join(MODEL_DIR, 'best_scaler.pkl'))
        
        with open(os.path.join(MODEL_DIR, 'best_model_metadata.json'), 'r') as f:
            metadata = json.load(f)
        
        return model, scaler, metadata, True
    except Exception as e:
        return None, None, None, False

model, scaler, metadata, model_loaded = load_model()

# ============================================
# HEADER
# ============================================
st.title("üêõ Bug Predictor")
st.markdown("**Syst√®me Intelligent de Pr√©diction de Bugs**")
st.markdown("*Par : EZZAIM Saloua & ER-REMYTY Karima | Encadrante : Pr. MJAHED Soukaina*")
st.markdown("---")

# ============================================
# SIDEBAR
# ============================================
st.sidebar.title("üìå Navigation")
page = st.sidebar.radio(
    "S√©lectionner une page",
    ["üè† Accueil", "üîÆ Pr√©diction", "üìä Performances"]
)

st.sidebar.markdown("---")

if model_loaded:
    st.sidebar.success("‚úÖ Mod√®le charg√©")
    st.sidebar.metric("Accuracy", f"{metadata['accuracy']:.2f}%")
    st.sidebar.metric("Recall", f"{metadata['recall']:.2f}%")
    st.sidebar.metric("F1-Score", f"{metadata['f1_score']:.2f}%")
else:
    st.sidebar.error("‚ùå Mod√®le non disponible")

# ============================================
# PAGE 1 : ACCUEIL
# ============================================
if page == "üè† Accueil":
    
    # M√©triques principales
    col1, col2, col3, col4 = st.columns(4)
    
    if model_loaded:
        col1.metric("üéØ Accuracy", f"{metadata['accuracy']:.2f}%", 
                    delta="‚úÖ Objectif: ‚â•70%")
        col2.metric("üìà Recall", f"{metadata['recall']:.2f}%")
        col3.metric("üé≤ F1-Score", f"{metadata['f1_score']:.2f}%")
        col4.metric("ü§ñ Mod√®le", metadata['model_name'].split('(')[0].strip())
    
    st.markdown("---")
    
    # Informations du projet
    st.subheader("üìã √Ä Propos du Projet")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("""
        **üéì Contexte Acad√©mique**
        
        - **Universit√© :** Cadi Ayyad
        - **Facult√© :** Sciences Semlalia
        - **Formation :** Master IA
        - **Ann√©e :** 2024-2025
        
        **üë• √âquipe**
        
        - EZZAIM Saloua
        - ER-REMYTY Karima
        
        **üë®‚Äçüè´ Encadrante**
        
        - Pr. MJAHED Soukaina
        """)
    
    with col2:
        st.success("""
        **üéØ Objectif**
        
        Pr√©dire automatiquement les fichiers √† risque dans un projet logiciel
        
        **üìä Dataset**
        
        - NASA Combined (13 projets)
        - 9,533 √©chantillons
        - 38 m√©triques de code
        
        **ü§ñ Mod√®le**
        
        - Random Forest Optimis√©
        - class_weight='balanced'
        - Accuracy: 84.01% ‚úÖ
        """)
    
    st.markdown("---")
    
    # M√©thodologie
    st.subheader("üõ†Ô∏è M√©thodologie & Organisation")
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "SCRUM", "UML", "Architecture", "Design Patterns", "Structure Code"
    ])
    
    with tab1:
        st.markdown("""
        ### üìã M√©thodologie SCRUM
        
        **Product Backlog :**
        - Epic 1 : Extraction et Analyse des Donn√©es
        - Epic 2 : Mod√®le de Pr√©diction
        - Epic 3 : Interface et Visualisation
        - Epic 4 : API et Int√©gration
        
        **Sprints (3 x 2 semaines) :**
        
        **Sprint 1 - Fondations :**
        - Setup environnement
        - Extraction donn√©es Git
        - Calcul m√©triques de complexit√©
        - Pipeline de pr√©paration
        
        **Sprint 2 - Mod√®le ML :**
        - Feature engineering
        - Entra√Ænement Random Forest
        - Comparaison algorithmes
        - Validation crois√©e
        
        **Sprint 3 - Interface :**
        - Dashboard Streamlit
        - Visualisations
        - Documentation
        - Tests finaux
        
        **Ceremonies SCRUM :**
        - Daily Stand-up (15 min/jour)
        - Sprint Planning (4h/sprint)
        - Sprint Review (2h/sprint)
        - Sprint Retrospective (1h30/sprint)
        """)
    
    with tab2:
        st.markdown("""
        ### üìê Conception UML
        
        **Diagrammes R√©alis√©s :**
        
        **1. Diagramme de Cas d'Utilisation**
        - Acteurs : D√©veloppeur, Chef de Projet, Syst√®me CI/CD
        - Cas d'usage : Analyser Projet, Visualiser Risques, G√©n√©rer Rapport
        
        **2. Diagramme de Classes**
        - DataExtractor (Abstract)
        - GitExtractor, SVNExtractor
        - FileAnalyzer
        - BugPredictor
        - PredictionStrategy (Interface)
        - Project, FileInfo, Report
        
        **3. Diagramme de S√©quence**
        - S√©quence : Analyse d'un projet
        - S√©quence : Entra√Ænement du mod√®le
        
        **4. Diagramme d'Activit√©**
        - Processus de pr√©diction complet
        
        **5. Diagramme de Composants**
        - Architecture en couches (Pr√©sentation, M√©tier, Donn√©es)
        """)
    
    with tab3:
        st.markdown("""
        ### üèóÔ∏è Architecture
        
        **Architecture Logique (MVC adapt√©) :**
```
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Couche Pr√©sentation           ‚îÇ
        ‚îÇ   (Streamlit Dashboard)         ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
        ‚îÇ   Couche M√©tier                 ‚îÇ
        ‚îÇ   (BugPredictor, Services)      ‚îÇ
        ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
        ‚îÇ   Couche Donn√©es                ‚îÇ
        ‚îÇ   (DataExtractor, CSV, Models)  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```
        
        **Architecture Physique :**
        
        - **Application Streamlit :** Port 8501
        - **Mod√®les ML :** Fichiers .pkl locaux
        - **Base de donn√©es :** CSV (data.csv)
        - **Figures :** PNG (visualisations)
        
        **Technologies :**
        
        - **Backend :** Python 3.10+
        - **ML :** Scikit-learn, imbalanced-learn
        - **Frontend :** Streamlit
        - **Data :** Pandas, NumPy
        - **Viz :** Matplotlib, Seaborn
        """)
    
    with tab4:
        st.markdown("""
        ### üé® Design Patterns
        
        **Patterns Utilis√©s :**
        
        **1. Strategy Pattern**
        - Interface : `PredictionStrategy`
        - Impl√©mentations : 
          - `RandomForestStrategy`
          - `SVMStrategy`
          - `GradientBoostingStrategy`
        - Permet de changer dynamiquement l'algorithme
        
        **2. Factory Pattern**
        - `DataExtractorFactory`
        - Cr√©e le bon extracteur (Git, SVN) selon le type
        
        **3. Singleton Pattern**
        - Classe `Config`
        - Une seule instance de configuration globale
        
        **4. Observer Pattern**
        - Notifications de progr√®s d'analyse
        - Mise √† jour de l'interface en temps r√©el
        
        **Justification :**
        - **Flexibilit√© :** Changer de mod√®le facilement
        - **Maintenabilit√© :** Code modulaire
        - **Extensibilit√© :** Ajouter de nouveaux algorithmes
        """)
    

    st.markdown("---")
    
    # Visualisations
    st.subheader("üìà Visualisations")
    
    try:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Distribution du Dataset**")
            img1 = Image.open(os.path.join(FIGURES_DIR, '01_dataset_distribution.png'))
            st.image(img1, use_container_width=True)
        
        with col2:
            st.markdown("**Performances du Mod√®le**")
            img2 = Image.open(os.path.join(FIGURES_DIR, '02_model_performance.png'))
            st.image(img2, use_container_width=True)
        
        st.markdown("**Comparaison des Mod√®les**")
        img3 = Image.open(os.path.join(FIGURES_DIR, '03_model_comparison.png'))
        st.image(img3, use_container_width=True)
        
    except:
        st.warning("‚ö†Ô∏è Visualisations non disponibles. Ex√©cutez generate_visualizations.py")

# ============================================
# PAGE 2 : PR√âDICTION
# ============================================
elif page == "üîÆ Pr√©diction":
    st.header("üîÆ Pr√©diction de Bugs")
    
    if not model_loaded:
        st.error("‚ùå Mod√®le non charg√©. Impossible de faire des pr√©dictions.")
        st.stop()
    
    # Charger les features
    df = pd.read_csv(os.path.join(DATA_DIR, 'data.csv'))
    df = df.dropna(subset=['Defective'])
    X = df.drop(columns=['Defective', 'source', 'label'], errors='ignore')
    feature_names = X.columns.tolist()
    
    st.info(f"üìã Le mod√®le utilise **{len(feature_names)} m√©triques** de code source.")
    
    # Onglets
    tab1, tab2 = st.tabs(["üì§ Upload CSV", "‚úçÔ∏è Saisie Manuelle"])
    
    # TAB 1 : Upload CSV
    with tab1:
        st.subheader("üì§ Uploader un fichier CSV")
        
        st.markdown("""
        **Format attendu :** Un fichier CSV contenant les 38 m√©triques de code.
        
        Les colonnes doivent correspondre aux features du mod√®le.
        """)
        
        uploaded_file = st.file_uploader("Choisir un fichier CSV", type=['csv'])
        
        if uploaded_file is not None:
            try:
                input_df = pd.read_csv(uploaded_file)
                st.success(f"‚úÖ Fichier charg√© : **{len(input_df)} fichiers**")
                
                # V√©rifier colonnes
                missing_cols = set(feature_names) - set(input_df.columns)
                
                if missing_cols:
                    st.error(f"‚ùå Colonnes manquantes : {missing_cols}")
                else:
                    # Bouton pr√©diction
                    if st.button("üîÆ Pr√©dire les Bugs", type="primary"):
                        with st.spinner("Pr√©diction en cours..."):
                            # Pr√©paration
                            input_scaled = scaler.transform(input_df[feature_names])
                            
                            # Pr√©dictions
                            predictions = model.predict(input_scaled)
                            probabilities = model.predict_proba(input_scaled)[:, 1]
                            
                            # R√©sultats
                            results_df = pd.DataFrame({
                                'Fichier': range(1, len(predictions)+1),
                                'Pr√©diction': ['üêõ BUG' if p == 1 else '‚úÖ OK' for p in predictions],
                                'Probabilit√© Bug (%)': (probabilities * 100).round(2),
                                'Niveau de Risque': [
                                    'üî¥ √âLEV√â' if prob > 0.7 
                                    else ('üü° MOYEN' if prob > 0.4 else 'üü¢ FAIBLE')
                                    for prob in probabilities
                                ]
                            })
                            
                            st.markdown("---")
                            st.subheader("üìä R√©sultats de la Pr√©diction")
                            
                            # M√©triques globales
                            col1, col2, col3 = st.columns(3)
                            
                            n_bugs = sum(predictions)
                            n_total = len(predictions)
                            n_high_risk = sum(probabilities > 0.7)
                            
                            col1.metric("Bugs D√©tect√©s", f"{n_bugs} / {n_total}")
                            col2.metric("Pourcentage", f"{n_bugs/n_total*100:.1f}%")
                            col3.metric("Risque √âlev√©", n_high_risk)
                            
                            # Table des r√©sultats
                            st.dataframe(results_df, use_container_width=True)
                            
                            # T√©l√©chargement
                            csv = results_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="üì• T√©l√©charger les r√©sultats (CSV)",
                                data=csv,
                                file_name="bug_predictions.csv",
                                mime="text/csv"
                            )
                
            except Exception as e:
                st.error(f"‚ùå Erreur : {e}")
    
    # TAB 2 : Saisie manuelle
    with tab2:
        st.subheader("‚úçÔ∏è Saisie Manuelle des M√©triques (Temps R√©el)")
        st.warning("‚ö†Ô∏è Les r√©sultats se mettent √† jour d√®s que vous modifiez une valeur.")

        col1, col2 = st.columns(2)
        inputs = {}

        main_features = [
            'LOC_TOTAL', 'CYCLOMATIC_COMPLEXITY', 'LOC_EXECUTABLE',
            'HALSTEAD_VOLUME', 'HALSTEAD_DIFFICULTY', 'NUMBER_OF_LINES',
            'LOC_COMMENTS', 'BRANCH_COUNT'
        ]

        for i, feature in enumerate(feature_names):
            if feature in main_features:
                if i % 2 == 0:
                    inputs[feature] = col1.number_input(
                        f"üìä {feature}", value=0.0, format="%.2f"
                    )
                else:
                    inputs[feature] = col2.number_input(
                        f"üìä {feature}", value=0.0, format="%.2f"
                    )
            else:
                inputs[feature] = 0.0  # Valeurs par d√©faut

        # Pr√©diction automatique
        try:
            input_df = pd.DataFrame([inputs])
            input_scaled = scaler.transform(input_df)

            prediction = model.predict(input_scaled)[0]
            probability = model.predict_proba(input_scaled)[0, 1]

            st.markdown("---")
            st.subheader("üìä R√©sultat")

            if prediction == 1:
                st.error(f"üêõ BUG d√©tect√© ({probability * 100:.2f}% de probabilit√©)")
            else:
                st.success(f"‚úÖ Pas de bug ({probability * 100:.2f}% de probabilit√©)")

        except Exception as e:
            st.error(f"‚ùå Erreur : {e}")

# ============================================
# PAGE 3 : PERFORMANCES
# ============================================
else:  # page == "üìä Performances"
    st.header("üìä Performances du Mod√®le")
    
    # Comparaison des mod√®les
    try:
        comparison_df = pd.read_csv(os.path.join(MODEL_DIR, 'model_comparison.csv'))
        
        st.subheader("üî¨ Comparaison des Algorithmes")
        
        st.dataframe(
            comparison_df.style.highlight_max(axis=0, subset=['Accuracy', 'Precision', 'Recall', 'F1-Score']),
            use_container_width=True
        )
        
        # Graphique de comparaison
        st.markdown("---")
        st.subheader("üìà Graphique Comparatif")
        
        import plotly.express as px
        
        fig = px.bar(
            comparison_df,
            x='Mod√®le',
            y=['Accuracy', 'Precision', 'Recall', 'F1-Score'],
            barmode='group',
            title='Comparaison des M√©triques par Mod√®le',
            labels={'value': 'Score (%)', 'variable': 'M√©trique'},
            color_discrete_sequence=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
        )
        
        fig.update_layout(
            xaxis_tickangle=-45,
            height=500,
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Meilleur mod√®le
        st.markdown("---")
        best_row = comparison_df.iloc[0]
        
        st.success(f"""
        ### üèÜ Meilleur Mod√®le : {best_row['Mod√®le']}
        
        - **Accuracy :** {best_row['Accuracy']:.2f}%
        - **Precision :** {best_row['Precision']:.2f}%
        - **Recall :** {best_row['Recall']:.2f}%
        - **F1-Score :** {best_row['F1-Score']:.2f}%
        - **Temps d'entra√Ænement :** {best_row['Temps (s)']:.2f}s
        """)
        
    except:
        st.error("‚ùå Fichier de comparaison non trouv√©")
    
    st.markdown("---")
    
    # M√©triques Train vs Test
    st.subheader("üèãÔ∏è Train vs Test")
    
    try:
        metrics_df = pd.read_csv(os.path.join(MODEL_DIR, 'metrics_comparison.csv'))
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üìö Entra√Ænement")
            for _, row in metrics_df.iterrows():
                st.metric(row['Metric'], f"{row['Train']*100:.2f}%")
        
        with col2:
            st.markdown("### üß™ Test")
            for _, row in metrics_df.iterrows():
                gap = (row['Train'] - row['Test']) * 100
                st.metric(
                    row['Metric'], 
                    f"{row['Test']*100:.2f}%",
                    delta=f"{gap:.2f}% gap",
                    delta_color="inverse"
                )
        
        # Diagnostic Overfitting
        st.markdown("---")
        st.subheader("üîç Diagnostic Overfitting")
        
        acc_gap = (metrics_df[metrics_df['Metric'] == 'Accuracy']['Train'].values[0] - 
                   metrics_df[metrics_df['Metric'] == 'Accuracy']['Test'].values[0]) * 100
        
        if acc_gap > 10:
            st.warning(f"‚ö†Ô∏è **Overfitting d√©tect√©** : √âcart de {acc_gap:.2f}% entre Train et Test")
        elif acc_gap > 5:
            st.info(f"‚ÑπÔ∏è **Overfitting l√©ger** : √âcart de {acc_gap:.2f}%")
        else:
            st.success(f"‚úÖ **Pas d'overfitting** : √âcart de {acc_gap:.2f}%")
    
    except:
        st.warning("‚ö†Ô∏è M√©triques de comparaison non disponibles")
    
    st.markdown("---")
    
    # Atteinte des objectifs
    st.subheader("üéØ Atteinte des Objectifs")
    
    if model_loaded:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if metadata['accuracy'] >= 70:
                st.success(f"""
                **‚úÖ OBJECTIF ATTEINT**
                
                Accuracy : {metadata['accuracy']:.2f}% ‚â• 70%
                """)
            else:
                st.error(f"""
                **‚ùå Objectif non atteint**
                
                Accuracy : {metadata['accuracy']:.2f}% < 70%
                """)
        
        with col2:
            if metadata['recall'] >= 50:
                st.success(f"""
                **‚úÖ RECALL EXCELLENT**
                
                {metadata['recall']:.2f}% ‚â• 50%
                """)
            elif metadata['recall'] >= 40:
                st.info(f"""
                **‚ÑπÔ∏è RECALL ACCEPTABLE**
                
                {metadata['recall']:.2f}% (40-50%)
                """)
            else:
                st.warning(f"""
                **‚ö†Ô∏è RECALL FAIBLE**
                
                {metadata['recall']:.2f}% < 40%
                """)
        
        with col3:
            st.info(f"""
            **üìä F1-SCORE**
            
            {metadata['f1_score']:.2f}%
            
            (√âquilibre Precision/Recall)
            """)

# ============================================
# FOOTER
# ============================================
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray; padding: 1rem;'>
    <p>¬© 2024-2025 Bug Predictor | Universit√© Cadi Ayyad - FSS Marrakech</p>
    <p>D√©velopp√© par EZZAIM Saloua & ER-REMYTY Karima</p>
</div>
""", unsafe_allow_html=True)